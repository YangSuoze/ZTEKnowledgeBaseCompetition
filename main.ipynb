{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取比赛所有的pdf并向量化后存入es数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob2\n",
    "files_path = glob2.glob('/Users/yangjie/Documents/python_project/zhongxing/参考文献/*')\n",
    "print(files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "def convert_pdf2txt(file_path):\n",
    "    client_f = OpenAI(\n",
    "        api_key=\"sk-rM8bGJ3AOHI5hR9NhL3SVqi31aDJfIIs36Xbl55RENZekM9S\",\n",
    "        base_url=\"https://api.moonshot.cn/v1\",\n",
    "    )\n",
    "    file_object = client_f.files.create(\n",
    "        file=Path(file_path), purpose=\"file-extract\"\n",
    "    )\n",
    "    file_content = json.loads(\n",
    "        client_f.files.content(file_id=file_object.id).text\n",
    "    )\n",
    "    fnw = os.path.splitext(file_path)[0] + \".txt\"\n",
    "    with open(fnw, \"w\") as file:\n",
    "        file.write(str(file_content[\"content\"]))\n",
    "\n",
    "for file_path in files_path:\n",
    "    convert_pdf2txt(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切分文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_split import ChineseRecursiveTextSplitter\n",
    "text_splitter = ChineseRecursiveTextSplitter(\n",
    "    keep_separator=True, is_separator_regex=True, chunk_size=1000, chunk_overlap=50\n",
    ")\n",
    "def get_text_from_txt(file_path):\n",
    "    input_text = ''\n",
    "    with open(file_path,'r',encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        input_text += '\\n'.join(lines)\n",
    "    return input_text\n",
    "files_path_cn = [\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/cn202303.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/cn202304.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/cn202305.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/cn202306.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/cn202401.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/cn202402.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/jx202311.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/jx202312.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/jx202401.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/jx202402.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/jx202403.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/jx202404.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/jx202405.txt',\n",
    "]\n",
    "files_path_en = [\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/en202303.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/en202304.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/en202401.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/ZTE TECHNOLOGIES (No.1) 2024.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/ZTE TECHNOLOGIES (No.2) 2024.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/ZTE TECHNOLOGIES (No.3) 2023.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/ZTE TECHNOLOGIES (No.3) 2024.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/ZTE TECHNOLOGIES (No.4) 2023.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/ZTE TECHNOLOGIES (No.5) 2023.txt',\n",
    "    '/Users/yangjie/Documents/python_project/zhongxing/参考文献/ZTE TECHNOLOGIES (No.6) 2023.txt',\n",
    "]\n",
    "ls_cn,ls_en = [],[]\n",
    "chunks_cn,chunks_en = [],[]\n",
    "for file_path in files_path_cn:\n",
    "    ls_cn.append(get_text_from_txt(file_path))\n",
    "for inum, text in enumerate(ls_cn):\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    for chunk in chunks:\n",
    "        chunks_cn.append(chunk)\n",
    "for file_path in files_path_en:\n",
    "    ls_en.append(get_text_from_txt(file_path))\n",
    "for inum, text in enumerate(ls_en):\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    for chunk in chunks:\n",
    "        chunks_en.append(chunk)\n",
    "\n",
    "print(len(chunks_cn))\n",
    "print(len(chunks_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量化入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from es_kb_service import ESKBService\n",
    "esKBService = ESKBService()\n",
    "data_list = chunks_en\n",
    "esKBService.do_add_doc(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据语句检索数据库内容判断对错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions():\n",
    "    import csv\n",
    "    csv_file_path = '/Users/yangjie/Documents/python_project/zhongxing/test_B.csv'\n",
    "    questions = []\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            questions.append(row['question'])\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "def post_query(query):\n",
    "    model = ChatOpenAI(\n",
    "            openai_api_key=\"sk-b3RjMZgQjoCCQzqA2dD4F232532645Ab9948062611E45171\",\n",
    "            openai_api_base=\"http://10.120.18.242:30387/v1\",\n",
    "            model_name=\"qwen2-72b\",\n",
    "            temperature=0.2,\n",
    "        )\n",
    "    model = ChatOpenAI(\n",
    "            openai_api_key=\"EMPTY\",\n",
    "            openai_api_base='http://10.13.14.16:7863/v1',\n",
    "            model_name='glm-4-9b-chat',\n",
    "            temperature=0.2, \n",
    "            model_kwargs={\"stop\": [\"<|endoftext|>\", \"<|user|>\", \"<|observation|>\"], \"extra_body\": {\"skip_special_tokens\": False}}  \n",
    "        )\n",
    "    answer = model.invoke(query).content\n",
    "    return answer\n",
    "\n",
    "# import os\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# from typing import List, Literal, Optional, Callable, Generator, Dict, Any, Awaitable, Union\n",
    "\n",
    "# thread_pool = ThreadPoolExecutor(os.cpu_count())\n",
    "\n",
    "# def run_in_thread_pool_v2(\n",
    "#     func: Callable,\n",
    "#     params: List[Dict] = [],\n",
    "#     pool: ThreadPoolExecutor = None,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     在线程池中批量运行任务，并将运行结果以生成器的形式返回。\n",
    "#     请确保任务中的所有操作是线程安全的，任务函数请全部使用关键字参数。\n",
    "#     \"\"\"\n",
    "#     tasks = []\n",
    "#     pool = ThreadPoolExecutor(os.cpu_count())\n",
    "\n",
    "#     for kwargs in params:\n",
    "#         thread = pool.submit(func, **kwargs)\n",
    "#         tasks.append(thread)\n",
    "#     results = []\n",
    "#     for obj in as_completed(tasks):\n",
    "#         results.append(obj.result())\n",
    "#     return results\n",
    "print(post_query('你好'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(answer):\n",
    "    answer = answer.split('。')[0]\n",
    "    if '正确' in answer:\n",
    "        res = 'T'\n",
    "    elif '错误' in answer:\n",
    "        res = 'F'\n",
    "    else:\n",
    "        res = '未知'\n",
    "    return res\n",
    "def get_self_consistence_answer(input_query,num):\n",
    "    from collections import Counter\n",
    "    answers = []\n",
    "    for _ in range(num):\n",
    "        answers += [get_answer(post_query(input_query))]\n",
    "    counter = Counter(answers)\n",
    "    most_common_element, _ = counter.most_common(1)[0]\n",
    "    return most_common_element\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检索相关文档chunks并进行重排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from es_kb_service import ESKBService\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "query_list = get_questions()\n",
    "res_list = []\n",
    "\n",
    "def get_answer_from_LLM(query):\n",
    "    print('query:',query)\n",
    "    # 检索之前先对问题进行翻译\n",
    "    input_query = f\"\"\"请将以下句子进行翻译，如果用户输入是中文就翻译成英文，如果用户输入是英文就翻译成中文。\n",
    "【注意】直接输出翻译结果，不要输出其他多余的内容\n",
    "\n",
    "用户输入：{query}\n",
    "\"\"\"\n",
    "    answer_tans = post_query(input_query)\n",
    "    print(answer_tans)\n",
    "    esKBService = ESKBService()\n",
    "    docs = esKBService.do_search(query+answer_tans,top_k=50)\n",
    "    # 对检索出来的docs进行重排序\n",
    "    # reranker = FlagReranker(\"BAAI/bge-reranker-large\", use_fp16=True)\n",
    "    # scores = reranker.compute_score(\n",
    "    #     [[query+answer_tans, doc.page_content] for doc in docs]\n",
    "    # )\n",
    "    # docs = [\n",
    "    #     doc\n",
    "    #     for doc, _ in sorted(\n",
    "    #         zip(docs, scores), key=lambda pair: pair[1], reverse=True\n",
    "    #     )\n",
    "    # ][:50]\n",
    "    # 调用大模型给出判断\n",
    "    context = ''\n",
    "    for inum, doc in enumerate(docs):\n",
    "        doc = doc.replace('\\n','')\n",
    "        context += f\"\"\"知识 [{inum}]： {doc}\\n\"\"\"\n",
    "    input_query = f\"\"\"你是一个做判断题的能手，请结合给定的知识，判断用户输入的语句是否正确，如果参考文档中未提及则不算错误\n",
    "【注意】回答格式请统一输出，如：\n",
    "如果选项正确，则输出：正确。原因是***\n",
    "如果选项错误，则输出：错误。原因是***\n",
    "【注意】回答请精简准确，不超过50字，注意一定要谨慎小心可能错误的选项，并结合已有的常识综合进行判断。\n",
    "\n",
    "<参考消息>\n",
    "{context}\n",
    "<参考消息>\n",
    "\n",
    "用户输入：{query}\n",
    "\"\"\"\n",
    "    # print(input_query)\n",
    "    answer = get_self_consistence_answer(input_query,5)\n",
    "    # answer = post_query(input_query)\n",
    "    print(answer)\n",
    "    return answer\n",
    "\n",
    "for i in range(0,100):\n",
    "    print(f'第{i+1}题......')\n",
    "    res = get_answer_from_LLM(query_list[i])\n",
    "    res_list+=[res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换得到结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从答案列表中转换TF\n",
    "TF_list = []\n",
    "for answer in res_list:\n",
    "    answer = answer.split('。')[0]\n",
    "    if '正确' in answer:\n",
    "        TF_list.append('T')\n",
    "    elif '错误' in answer:\n",
    "        TF_list.append('F')\n",
    "    else:\n",
    "        TF_list.append('未知')\n",
    "print(TF_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_file_path = '/Users/yangjie/Documents/python_project/zhongxing/result_v2.csv'\n",
    "\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    row_to_write = ['id', 'answer']\n",
    "    writer.writerow(row_to_write)\n",
    "    for i,answer in enumerate(TF_list):\n",
    "        row_to_write = [i+1, answer]\n",
    "        writer.writerow(row_to_write)\n",
    "\n",
    "print(f\"数据已写入到文件：{csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "def post_query(query):\n",
    "    model = ChatOpenAI(\n",
    "            openai_api_key=\"sk-b3RjMZgQjoCCQzqA2dD4F232532645Ab9948062611E45171\",\n",
    "            openai_api_base=\"http://10.13.14.16:9999/v1\",\n",
    "            model_name=\"qwen2-72b\",\n",
    "            temperature=0.1,\n",
    "        )\n",
    "    answer = model.invoke(query).content\n",
    "    return answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
